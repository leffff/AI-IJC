{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aggressiveness_reasons.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"i8DGZDmdMXa5"},"source":["The main purpose of this file is to detect reasons of aggressive driving through user comments. </br>\n","To do that we are going to use </br>\n","1. A pretrained classification model that will detect comments describing aggressive driving\n","2. A Q&A model, which will get the reason of aggresssive driving through answering the following question: **\"как выражалось агрессивное вождение\"**"]},{"cell_type":"markdown","metadata":{"id":"LHSWVXc-LWhu"},"source":["# Settings"]},{"cell_type":"code","metadata":{"id":"6Vu1gxddRwWF"},"source":["# install neede libraries\n","!pip install transformers\n","!pip install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex_9C2WBcuVU"},"source":["# define device\n","import torch\n","from torch import nn\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EQ8HS4rL05bu"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"jCBW5VkegQPp"},"source":["#text preprocessig function\n","def remove_punkt(text: str) -> str:\n","    text = ''.join(map(lambda c: c if c.isalpha() else ' ', text.lower()))\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-WIA6lU8p7b"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"mirEO8tW3sch"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IRZXEdLDc1n"},"source":["import pandas as pd\n","train_labeled = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/Data_rus/labled_train_data.csv', index_col=0, sep=\"\\t\")\n","comments_labeled = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/Data_rus/labled_train_comments.csv', index_col=0, sep=\"\\t\")\n","\n","comments_unlabeled = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/Data_rus/unlabled_train_comments.csv', index_col=0, sep=\"\\t\")\n","\n","# pseudo_labeled = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/text_processing/pseudo_labeled_data/labeled_comments_clean_xlm_roberta_20_epochs.csv', index_col=0)\n","# pseudo_unlabeled = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/text_processing/pseudo_labeled_data/unlabeled_comments_clean_xlm_roberta_20_epochs.csv', index_col=0)\n","# whole_data = pseudo_labeled.append(pseudo_unlabeled)\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/Data_rus/labled_test_data.csv', index_col=0, sep=\"\\t\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mtd13aZ4Pts5"},"source":["Use only clean comments form test set"]},{"cell_type":"code","metadata":{"id":"nXUF7jnjNXOv"},"source":["test_comments = test.comment[(test.comment != \"Больше нечего сказать\") & (test.comment != \"Да\")]\n","test_comments"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8TfIn8J-qFm"},"source":["question = \"как выражалось агрессивное вождение\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2u0kR2HKG_tz"},"source":["# Classification"]},{"cell_type":"code","metadata":{"id":"Mqz0-r9F8RTk"},"source":["from transformers import AutoModel\n","from torch import nn\n","\n","\n","class XLMRobertaBaseClassifier(nn.Module):\n","    def __init__(self):\n","        super(XLMRobertaBaseClassifier, self).__init__()\n","        self.base_model = AutoModel.from_pretrained('sismetanin/xlm_roberta_base-ru-sentiment-rusentiment')\n","        self.Linear = nn.Linear(768, 2)\n","        \n","    def forward(self, input_ids, token_type_ids, attention_mask):\n","        outputs = self.base_model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n","        outputs = self.Linear(outputs)\n","\n","        return outputs\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"svRXriibLuzs"},"source":["## Load the best text classification model"]},{"cell_type":"code","metadata":{"id":"qxHOaqi-HMFg"},"source":["classification_model = XLMRobertaBaseClassifier()\n","classification_model.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/Контесты/AI IJC/team_tasks/task_2/text_processing/base_models/uda_xlm_roberta_base_3_epochs.h5\"))\n","classification_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NEDqde8sk3SV"},"source":["# Q&A"]},{"cell_type":"markdown","metadata":{"id":"YpSscOmG--Gv"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"sCk-9kadsGNK"},"source":["from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","import sentencepiece\n","\n","qa_model = AutoModelForQuestionAnswering.from_pretrained(\"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\", do_lower_case=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5lCBX73L8rQ0"},"source":["## Predictions"]},{"cell_type":"code","metadata":{"id":"mSVgFyRT9owu"},"source":["from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","import torch\n","\n","sigmoid = torch.nn.Sigmoid()\n","\n","\n","for comment in list(test_comments):\n","    clean_comment = remove_punkt(comment)\n","\n","    inputs = tokenizer(question, clean_comment, add_special_tokens=True, return_tensors=\"pt\")\n","\n","    input_ids = inputs[\"input_ids\"]\n","    attention_mask = inputs[\"attention_mask\"]\n","\n","    classification_output = classification_model(\n","        input_ids=input_ids.to(device), \n","        token_type_ids=None,\n","        attention_mask=attention_mask.to(device)\n","    )\n","    probas = sigmoid(classification_output)\n","    print(probas)\n","    if probas[:, 1] < 0.30:\n","        \n","        print(f\"Comment: {comment}\")\n","        print(f\"Answer: Нет причины агрессивного вождения\", end=\"\\n ------------------ \\n\")\n","\n","    else:\n","        qa_outputs = qa_model(\n","            input_ids=input_ids, \n","            token_type_ids=None,\n","            attention_mask=attention_mask\n","        )\n","\n","        answer_start_scores = qa_outputs.start_logits\n","        answer_end_scores = qa_outputs.end_logits\n","\n","        answer_start = torch.argmax(\n","            answer_start_scores\n","        )  # Get the most likely beginning of answer with the argmax of the score\n","        \n","        answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n","        ids = input_ids[0][answer_start:answer_end]\n","        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(ids))\n","\n","        clean_answer = answer.replace(\"<s>\", \" \").replace(\"</s>\", \" \").replace(question, \"\").strip()\n","        if clean_answer == \"\":\n","            clean_answer = \"Причина агрессивного вождения не распознана\"\n","\n","        print(f\"Comment: {comment}\")\n","        # print(f\"Question: {question}\")\n","        print(f\"Answer: {clean_answer}\", end=\"\\n ------------------ \\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6P0X-hRK7zR"},"source":[""],"execution_count":null,"outputs":[]}]}